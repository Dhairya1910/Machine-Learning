{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bf5364",
   "metadata": {},
   "source": [
    "# implemention of a deep neural network with its Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fd8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNet:\n",
    "\n",
    "    def __init__(self,input_size,hidden_size,output_size,Lambda=0.05,learning_rate=0.001,epoches=1000,hidden_layer=1):\n",
    "\n",
    "        \"\"\"initialization of parameters \"\"\"\n",
    "        self.input_size = input_size # number of parameters \n",
    "        self.hidden_size = hidden_size # number of neurons in hidden layers \n",
    "        self.output_size = output_size # size of output \n",
    "        self.Lambda = Lambda # for regularization \n",
    "        self.learning_rate = learning_rate # learning rate \n",
    "        self.epoches = epoches # number of iterations \n",
    "        self.hidden_layer = hidden_layer # number of hidden layer \n",
    "        \n",
    "        \"\"\"initialization of hidden layers\"\"\"\n",
    "\n",
    "        self.HW = [np.random.randn(self.input_size,self.hidden_size)]\n",
    "        self.HB = [np.zeros((1,self.hidden_size))] \n",
    "\n",
    "        for layers in range(self.hidden_layer): # iterativly add new hidden layer parameters\n",
    "            self.HW.append(np.random.randn(self.hidden_size,self.hidden_size))\n",
    "            self.HB.append(np.zeros((1,self.hidden_size)))\n",
    "        \n",
    "        \"\"\"initialization of Output layer\"\"\"\n",
    "\n",
    "        self.OW = np.random.randn(self.hidden_size,self.output_size)\n",
    "        self.OB = np.zeros((1,self.output_size))\n",
    "\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        return 1 / (1+np.exp(-z)) \n",
    "    \n",
    "    def derivative_sigmoid(self,z):\n",
    "        s = self.sigmoid(z) \n",
    "        return s * (1-s)\n",
    "    \n",
    "    def Relu(self,z):\n",
    "        return np.maximum(0,z)\n",
    "    \n",
    "    def derivative_relu(self,z):\n",
    "        return (z>0).astype(float)\n",
    "    \n",
    "    def compute_loss(self,preds,Y):\n",
    "        return -np.mean(Y*np.log(preds)+(1-Y)*np.log(1-preds))\n",
    "    \n",
    "    def ForwardPropagation(self,X):\n",
    "        A = X \n",
    "        self.HZ = []\n",
    "        self.HA = [A]\n",
    "\n",
    "        \"\"\"moving deep inside neural networks,calculation from 1 to L-1 layers \"\"\"\n",
    "        for l in range(self.hidden_layer):\n",
    "            Z = np.dot(A,self.HW[l]) + self.HB[l] \n",
    "            self.HZ.append(Z)\n",
    "            A = self.Relu(Z)\n",
    "            self.HA.append(A)\n",
    "\n",
    "        \"\"\"Calculation for Output layer \"\"\" \n",
    "        self.OZ = np.dot(self.HA[-1],self.OW) + self.OB \n",
    "        self.OA = self.sigmoid(self.OZ)\n",
    "\n",
    "        return self.OA \n",
    "    \n",
    "    def BackwardPropagation(self,X,Y):\n",
    "        m = X.shape[0]\n",
    "        error = self.OA - Y \n",
    "\n",
    "        \"\"\"Moving Backward from output layer\"\"\"\n",
    "        DOW = 1/m * np.dot(self.HA[-1].T,error) + self.Lambda * self.OW\n",
    "        DOB = 1/m * np.sum(error,axis=0,keepdims=True)\n",
    "\n",
    "        self.OW = self.OW - self.learning_rate * DOW \n",
    "        self.OB = self.OB - self.learning_rate * DOB \n",
    "\n",
    "        \"\"\"moving backward in hidden layers\"\"\"\n",
    "        for l in reversed(range(self.hidden_layer)):\n",
    "            DA = np.dot(error,self.OW.T if l == self.hidden_layer-1 else self.HW[l+1].T)\n",
    "            DZ = DA * self.derivative_relu(self.HZ[l]) \n",
    "            DW = 1/m * np.dot(self.HA[l].T,DZ) + self.Lambda * self.HW[l]\n",
    "            DB = 1/m * np.sum(DZ,axis=0,keepdims=True)\n",
    "\n",
    "            error = DZ \n",
    "            self.HW[l] = self.HW[l] - self.learning_rate * DW \n",
    "            self.HB[l] = self.HB[l] - self.learning_rate * DB \n",
    "\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        Y = np.array(Y).reshape(-1,1)\n",
    "\n",
    "        for epoch in range(self.epoches):\n",
    "            pred = self.ForwardPropagation(X)\n",
    "            loss = self.compute_loss(pred,Y)\n",
    "            print(f\"epoch : {epoch}, loss = {loss}\") \n",
    "            self.BackwardPropagation(X,Y) \n",
    "            \n",
    "    def predict(self,X):\n",
    "        return (self.ForwardPropagation(X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa5185ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss = 0.8437665885600472\n",
      "epoch : 1, loss = 0.8409079320177331\n",
      "epoch : 2, loss = 0.8381002230620227\n",
      "epoch : 3, loss = 0.8353244723075998\n",
      "epoch : 4, loss = 0.832579999239883\n",
      "epoch : 5, loss = 0.8298661394940076\n",
      "epoch : 6, loss = 0.8271822444842761\n",
      "epoch : 7, loss = 0.8245276810398988\n",
      "epoch : 8, loss = 0.8219018310470855\n",
      "epoch : 9, loss = 0.8193040910975351\n",
      "epoch : 10, loss = 0.8167338721433639\n",
      "epoch : 11, loss = 0.8141905991584784\n",
      "epoch : 12, loss = 0.811673710806418\n",
      "epoch : 13, loss = 0.8091826591146621\n",
      "epoch : 14, loss = 0.80671690915538\n",
      "epoch : 15, loss = 0.8042759387326216\n",
      "epoch : 16, loss = 0.8018592380759043\n",
      "epoch : 17, loss = 0.7994663095401685\n",
      "epoch : 18, loss = 0.797096667312053\n",
      "epoch : 19, loss = 0.7947498371224424\n",
      "epoch : 20, loss = 0.7924253559652281\n",
      "epoch : 21, loss = 0.790122771822222\n",
      "epoch : 22, loss = 0.7878416433941537\n",
      "epoch : 23, loss = 0.785581539837683\n",
      "epoch : 24, loss = 0.7833420405083485\n",
      "epoch : 25, loss = 0.7811227347093738\n",
      "epoch : 26, loss = 0.7789232214462521\n",
      "epoch : 27, loss = 0.7767431091870175\n",
      "epoch : 28, loss = 0.7745820156281231\n",
      "epoch : 29, loss = 0.7724395674658292\n",
      "epoch : 30, loss = 0.770315400173015\n",
      "epoch : 31, loss = 0.768209157781318\n",
      "epoch : 32, loss = 0.7661204926685073\n",
      "epoch : 33, loss = 0.7640490653509991\n",
      "epoch : 34, loss = 0.7619945442814103\n",
      "epoch : 35, loss = 0.759956605651067\n",
      "epoch : 36, loss = 0.7579349331973548\n",
      "epoch : 37, loss = 0.7559292180158326\n",
      "epoch : 38, loss = 0.7539391583769947\n",
      "epoch : 39, loss = 0.7519644595476016\n",
      "epoch : 40, loss = 0.7500048336164724\n",
      "epoch : 41, loss = 0.7480599993246471\n",
      "epoch : 42, loss = 0.7461296818998269\n",
      "epoch : 43, loss = 0.7442136128949919\n",
      "epoch : 44, loss = 0.7423115300311109\n",
      "epoch : 45, loss = 0.7404231770438455\n",
      "epoch : 46, loss = 0.7385483035341582\n",
      "epoch : 47, loss = 0.7366866648227378\n",
      "epoch : 48, loss = 0.7348380218081513\n",
      "epoch : 49, loss = 0.7330021408286299\n",
      "epoch : 50, loss = 0.7311787935274146\n",
      "epoch : 51, loss = 0.7293677567215622\n",
      "epoch : 52, loss = 0.7275688122741413\n",
      "epoch : 53, loss = 0.7257817469697241\n",
      "epoch : 54, loss = 0.7240063523931034\n",
      "epoch : 55, loss = 0.722242424811149\n",
      "epoch : 56, loss = 0.7204897650577271\n",
      "epoch : 57, loss = 0.7187481784216091\n",
      "epoch : 58, loss = 0.7170174745372893\n",
      "epoch : 59, loss = 0.7153033596766001\n",
      "epoch : 60, loss = 0.7136559989434541\n",
      "epoch : 61, loss = 0.7120177495557475\n",
      "epoch : 62, loss = 0.7103884485514445\n",
      "epoch : 63, loss = 0.7087679367672907\n",
      "epoch : 64, loss = 0.7071560587418773\n",
      "epoch : 65, loss = 0.7055526626213853\n",
      "epoch : 66, loss = 0.7039576000679378\n",
      "epoch : 67, loss = 0.7023707261704906\n",
      "epoch : 68, loss = 0.7007918993581835\n",
      "epoch : 69, loss = 0.6992209813160921\n",
      "epoch : 70, loss = 0.6976578369033019\n",
      "epoch : 71, loss = 0.6961023340732515\n",
      "epoch : 72, loss = 0.6945543437962703\n",
      "epoch : 73, loss = 0.6930137399842546\n",
      "epoch : 74, loss = 0.6914803994174198\n",
      "epoch : 75, loss = 0.6899542016730689\n",
      "epoch : 76, loss = 0.6884350290563224\n",
      "epoch : 77, loss = 0.6869227665327509\n",
      "epoch : 78, loss = 0.6854173016628566\n",
      "epoch : 79, loss = 0.6839185245383546\n",
      "epoch : 80, loss = 0.6824263277201941\n",
      "epoch : 81, loss = 0.6809406061782807\n",
      "epoch : 82, loss = 0.6794612572328421\n",
      "epoch : 83, loss = 0.677988180497394\n",
      "epoch : 84, loss = 0.6765212778232578\n",
      "epoch : 85, loss = 0.6750604532455912\n",
      "epoch : 86, loss = 0.67360561293088\n",
      "epoch : 87, loss = 0.672156665125855\n",
      "epoch : 88, loss = 0.6707135201077911\n",
      "epoch : 89, loss = 0.6692760901361483\n",
      "epoch : 90, loss = 0.6678442894055174\n",
      "epoch : 91, loss = 0.6664180339998309\n",
      "epoch : 92, loss = 0.6649972418478038\n",
      "epoch : 93, loss = 0.663581832679569\n",
      "epoch : 94, loss = 0.6621717279844723\n",
      "epoch : 95, loss = 0.6607668509699938\n",
      "epoch : 96, loss = 0.6593671265217631\n",
      "epoch : 97, loss = 0.6579724811646371\n",
      "epoch : 98, loss = 0.6565828430248098\n",
      "epoch : 99, loss = 0.6551981417929232\n",
      "epoch : 100, loss = 0.6538183086881532\n",
      "epoch : 101, loss = 0.6524432764232387\n",
      "epoch : 102, loss = 0.6510729791704309\n",
      "epoch : 103, loss = 0.6497073525283319\n",
      "epoch : 104, loss = 0.6483463334896002\n",
      "epoch : 105, loss = 0.6469898604095006\n",
      "epoch : 106, loss = 0.6456378729752643\n",
      "epoch : 107, loss = 0.6442903121762492\n",
      "epoch : 108, loss = 0.6429471202748671\n",
      "epoch : 109, loss = 0.6416082407782621\n",
      "epoch : 110, loss = 0.6402736184107137\n",
      "epoch : 111, loss = 0.6389431990867483\n",
      "epoch : 112, loss = 0.6376169298849382\n",
      "epoch : 113, loss = 0.6362947590223634\n",
      "epoch : 114, loss = 0.6349766358297254\n",
      "epoch : 115, loss = 0.6336625107270873\n",
      "epoch : 116, loss = 0.6323523352002275\n",
      "epoch : 117, loss = 0.6310460617775857\n",
      "epoch : 118, loss = 0.6297436440077866\n",
      "epoch : 119, loss = 0.6285218359089582\n",
      "epoch : 120, loss = 0.6274533195720133\n",
      "epoch : 121, loss = 0.6263877409669216\n",
      "epoch : 122, loss = 0.6253250546254678\n",
      "epoch : 123, loss = 0.6242652159973229\n",
      "epoch : 124, loss = 0.6232081814306609\n",
      "epoch : 125, loss = 0.6221539081532577\n",
      "epoch : 126, loss = 0.6211023542540544\n",
      "epoch : 127, loss = 0.6200534786651768\n",
      "epoch : 128, loss = 0.6190072411443975\n",
      "epoch : 129, loss = 0.6179636022580262\n",
      "epoch : 130, loss = 0.616922523364221\n",
      "epoch : 131, loss = 0.6158839665967083\n",
      "epoch : 132, loss = 0.6148478948488936\n",
      "epoch : 133, loss = 0.613814271758366\n",
      "epoch : 134, loss = 0.6127830616917718\n",
      "epoch : 135, loss = 0.6117542297300571\n",
      "epoch : 136, loss = 0.6107277416540657\n",
      "epoch : 137, loss = 0.6097035639304823\n",
      "epoch : 138, loss = 0.6086816636981119\n",
      "epoch : 139, loss = 0.6076620087544914\n",
      "epoch : 140, loss = 0.606644567542815\n",
      "epoch : 141, loss = 0.6056293091391742\n",
      "epoch : 142, loss = 0.6046162032400985\n",
      "epoch : 143, loss = 0.6036052201503913\n",
      "epoch : 144, loss = 0.6025963307712529\n",
      "epoch : 145, loss = 0.6015895065886813\n",
      "epoch : 146, loss = 0.6005847196621462\n",
      "epoch : 147, loss = 0.5995819426135259\n",
      "epoch : 148, loss = 0.598581148616304\n",
      "epoch : 149, loss = 0.597582311385014\n",
      "epoch : 150, loss = 0.5965854051649311\n",
      "epoch : 151, loss = 0.5956166643754583\n",
      "epoch : 152, loss = 0.595238802935645\n",
      "epoch : 153, loss = 0.5948618608721644\n",
      "epoch : 154, loss = 0.5944858294396002\n",
      "epoch : 155, loss = 0.59411069998555\n",
      "epoch : 156, loss = 0.5937364639495648\n",
      "epoch : 157, loss = 0.5933631128620933\n",
      "epoch : 158, loss = 0.5929906383434465\n",
      "epoch : 159, loss = 0.59261903210277\n",
      "epoch : 160, loss = 0.5922482859370317\n",
      "epoch : 161, loss = 0.5918783917300213\n",
      "epoch : 162, loss = 0.5915093414513606\n",
      "epoch : 163, loss = 0.5911411271555292\n",
      "epoch : 164, loss = 0.5907737409808989\n",
      "epoch : 165, loss = 0.5904071751487805\n",
      "epoch : 166, loss = 0.5900414219624848\n",
      "epoch : 167, loss = 0.5896764738063922\n",
      "epoch : 168, loss = 0.5893123231450343\n",
      "epoch : 169, loss = 0.5889489625221885\n",
      "epoch : 170, loss = 0.5885863845599806\n",
      "epoch : 171, loss = 0.5882245819580014\n",
      "epoch : 172, loss = 0.5878635474924322\n",
      "epoch : 173, loss = 0.5875032740151807\n",
      "epoch : 174, loss = 0.5871437544530297\n",
      "epoch : 175, loss = 0.5867849818067933\n",
      "epoch : 176, loss = 0.5864269491504845\n",
      "epoch : 177, loss = 0.5860696496304943\n",
      "epoch : 178, loss = 0.5857130764647788\n",
      "epoch : 179, loss = 0.5853572229420554\n",
      "epoch : 180, loss = 0.5850020824210127\n",
      "epoch : 181, loss = 0.5846476483295254\n",
      "epoch : 182, loss = 0.584293914163882\n",
      "epoch : 183, loss = 0.5839408734880195\n",
      "epoch : 184, loss = 0.5835885199327682\n",
      "epoch : 185, loss = 0.5832368471951069\n",
      "epoch : 186, loss = 0.5828858490374252\n",
      "epoch : 187, loss = 0.5825355192867951\n",
      "epoch : 188, loss = 0.5821858518342518\n",
      "epoch : 189, loss = 0.581836840634083\n",
      "epoch : 190, loss = 0.5814884797031272\n",
      "epoch : 191, loss = 0.5811407631200786\n",
      "epoch : 192, loss = 0.5807936850248033\n",
      "epoch : 193, loss = 0.5804472396176603\n",
      "epoch : 194, loss = 0.5801014211588336\n",
      "epoch : 195, loss = 0.5797562239676707\n",
      "epoch : 196, loss = 0.5794116424220284\n",
      "epoch : 197, loss = 0.579067670957629\n",
      "epoch : 198, loss = 0.5787243040674208\n",
      "epoch : 199, loss = 0.5783815363009487\n",
      "epoch : 200, loss = 0.5780393622637315\n",
      "epoch : 201, loss = 0.5776977766166469\n",
      "epoch : 202, loss = 0.5773567740753225\n",
      "epoch : 203, loss = 0.5770163494095354\n",
      "epoch : 204, loss = 0.5766764974426193\n",
      "epoch : 205, loss = 0.5763372130508768\n",
      "epoch : 206, loss = 0.5759984911630007\n",
      "epoch : 207, loss = 0.5756603267594999\n",
      "epoch : 208, loss = 0.5753227148721347\n",
      "epoch : 209, loss = 0.5749856505833562\n",
      "epoch : 210, loss = 0.5746491290257548\n",
      "epoch : 211, loss = 0.5743131453815128\n",
      "epoch : 212, loss = 0.573977694881865\n",
      "epoch : 213, loss = 0.5736427728065654\n",
      "epoch : 214, loss = 0.5733083744833599\n",
      "epoch : 215, loss = 0.5729744952874651\n",
      "epoch : 216, loss = 0.5726411306410533\n",
      "epoch : 217, loss = 0.5723082760127441\n",
      "epoch : 218, loss = 0.5719759269171015\n",
      "epoch : 219, loss = 0.5716440789141364\n",
      "epoch : 220, loss = 0.5713127276088154\n",
      "epoch : 221, loss = 0.570981868650576\n",
      "epoch : 222, loss = 0.5706514977328464\n",
      "epoch : 223, loss = 0.5703216105925715\n",
      "epoch : 224, loss = 0.5699922030097434\n",
      "epoch : 225, loss = 0.5696632708069401\n",
      "epoch : 226, loss = 0.5693348098488655\n",
      "epoch : 227, loss = 0.5690068160418985\n",
      "epoch : 228, loss = 0.5686792853336451\n",
      "epoch : 229, loss = 0.5683522137124964\n",
      "epoch : 230, loss = 0.5680255972071918\n",
      "epoch : 231, loss = 0.5676994318863874\n",
      "epoch : 232, loss = 0.5673737138582285\n",
      "epoch : 233, loss = 0.5670484392699292\n",
      "epoch : 234, loss = 0.566723604307353\n",
      "epoch : 235, loss = 0.566399205194603\n",
      "epoch : 236, loss = 0.566075238193613\n",
      "epoch : 237, loss = 0.5657516996037454\n",
      "epoch : 238, loss = 0.5654285857613925\n",
      "epoch : 239, loss = 0.565105893039584\n",
      "epoch : 240, loss = 0.564783617847597\n",
      "epoch : 241, loss = 0.5644617566305722\n",
      "epoch : 242, loss = 0.5641403058691334\n",
      "epoch : 243, loss = 0.5638192620790121\n",
      "epoch : 244, loss = 0.5634986218106753\n",
      "epoch : 245, loss = 0.5631783816489597\n",
      "epoch : 246, loss = 0.5628585382127079\n",
      "epoch : 247, loss = 0.562539088154409\n",
      "epoch : 248, loss = 0.5622200281598455\n",
      "epoch : 249, loss = 0.5619013549477414\n",
      "epoch : 250, loss = 0.5615830652694155\n",
      "epoch : 251, loss = 0.5612651559084396\n",
      "epoch : 252, loss = 0.5609476236802994\n",
      "epoch : 253, loss = 0.5606304654320587\n",
      "epoch : 254, loss = 0.5603136780420296\n",
      "epoch : 255, loss = 0.5599972584194444\n",
      "epoch : 256, loss = 0.5596812035041321\n",
      "epoch : 257, loss = 0.5593655102661983\n",
      "epoch : 258, loss = 0.559050175705709\n",
      "epoch : 259, loss = 0.5587351968523787\n",
      "epoch : 260, loss = 0.5584205707652589\n",
      "epoch : 261, loss = 0.5581062945324351\n",
      "epoch : 262, loss = 0.5577923652707228\n",
      "epoch : 263, loss = 0.5574787801253696\n",
      "epoch : 264, loss = 0.5571655362697585\n",
      "epoch : 265, loss = 0.5568526309051173\n",
      "epoch : 266, loss = 0.5565400612602291\n",
      "epoch : 267, loss = 0.5562278245911467\n",
      "epoch : 268, loss = 0.5559159181809096\n",
      "epoch : 269, loss = 0.5556043393392659\n",
      "epoch : 270, loss = 0.5552930854023961\n",
      "epoch : 271, loss = 0.5549821537326391\n",
      "epoch : 272, loss = 0.5546715417182237\n",
      "epoch : 273, loss = 0.5543612467730006\n",
      "epoch : 274, loss = 0.5540512663361794\n",
      "epoch : 275, loss = 0.5537415978720668\n",
      "epoch : 276, loss = 0.5534322388698096\n",
      "epoch : 277, loss = 0.5531231868431383\n",
      "epoch : 278, loss = 0.5528144393301164\n",
      "epoch : 279, loss = 0.5525059938928892\n",
      "epoch : 280, loss = 0.5521978481174394\n",
      "epoch : 281, loss = 0.5518899996133402\n",
      "epoch : 282, loss = 0.5515824460135165\n",
      "epoch : 283, loss = 0.551275184974006\n",
      "epoch : 284, loss = 0.5509682136723186\n",
      "epoch : 285, loss = 0.5506605816288606\n",
      "epoch : 286, loss = 0.5503532336967072\n",
      "epoch : 287, loss = 0.5500669906233254\n",
      "epoch : 288, loss = 0.5497980787742154\n",
      "epoch : 289, loss = 0.5495051707862559\n",
      "epoch : 290, loss = 0.5492434825618856\n",
      "epoch : 291, loss = 0.5489438387526776\n",
      "epoch : 292, loss = 0.548689439057668\n",
      "epoch : 293, loss = 0.5483834195718964\n",
      "epoch : 294, loss = 0.5481371820049238\n",
      "epoch : 295, loss = 0.5479724085713711\n",
      "epoch : 296, loss = 0.5477666164944222\n",
      "epoch : 297, loss = 0.5474521600542197\n",
      "epoch : 298, loss = 0.5471378748722737\n",
      "epoch : 299, loss = 0.5468237601987259\n",
      "epoch : 300, loss = 0.5466857111299458\n",
      "epoch : 301, loss = 0.5464544536239033\n",
      "epoch : 302, loss = 0.5461406238965298\n",
      "epoch : 303, loss = 0.5458269624458425\n",
      "epoch : 304, loss = 0.5455136024370145\n",
      "epoch : 305, loss = 0.5452686894196512\n",
      "epoch : 306, loss = 0.5451042605315866\n",
      "epoch : 307, loss = 0.5449009124041205\n",
      "epoch : 308, loss = 0.5445877895102255\n",
      "epoch : 309, loss = 0.5442748314720647\n",
      "epoch : 310, loss = 0.5439620375920784\n",
      "epoch : 311, loss = 0.5438200055109005\n",
      "epoch : 312, loss = 0.5435954467729469\n",
      "epoch : 313, loss = 0.5432829189437428\n",
      "epoch : 314, loss = 0.5429705532319384\n",
      "epoch : 315, loss = 0.5426583489622201\n",
      "epoch : 316, loss = 0.5425366688029657\n",
      "epoch : 317, loss = 0.5422929137857471\n",
      "epoch : 318, loss = 0.5419809675805592\n",
      "epoch : 319, loss = 0.5416691808566682\n",
      "epoch : 320, loss = 0.5413866471846278\n",
      "epoch : 321, loss = 0.5411141781029424\n",
      "epoch : 322, loss = 0.5409615662195\n",
      "epoch : 323, loss = 0.5407501529306424\n",
      "epoch : 324, loss = 0.5404388617176549\n",
      "epoch : 325, loss = 0.5401277269667447\n",
      "epoch : 326, loss = 0.5398168247315545\n",
      "epoch : 327, loss = 0.5395738616396455\n",
      "epoch : 328, loss = 0.5393889589337607\n",
      "epoch : 329, loss = 0.5392112027655898\n",
      "epoch : 330, loss = 0.5389005482484911\n",
      "epoch : 331, loss = 0.5385900473176206\n",
      "epoch : 332, loss = 0.5382796993682087\n",
      "epoch : 333, loss = 0.5381089454293227\n",
      "epoch : 334, loss = 0.5379180948730088\n",
      "epoch : 335, loss = 0.5376079790841879\n",
      "epoch : 336, loss = 0.5372980145758879\n",
      "epoch : 337, loss = 0.5369947302982846\n",
      "epoch : 338, loss = 0.5367824163856878\n",
      "epoch : 339, loss = 0.5366735559452203\n",
      "epoch : 340, loss = 0.5363714093951691\n",
      "epoch : 341, loss = 0.5360747906394219\n",
      "epoch : 342, loss = 0.5357835710477157\n",
      "epoch : 343, loss = 0.535523862908161\n",
      "epoch : 344, loss = 0.5352585193151819\n",
      "epoch : 345, loss = 0.5351425078462416\n",
      "epoch : 346, loss = 0.5348335740492703\n",
      "epoch : 347, loss = 0.5345420607612976\n",
      "epoch : 348, loss = 0.5343241236791834\n",
      "epoch : 349, loss = 0.5340394036191409\n",
      "epoch : 350, loss = 0.533763921690766\n",
      "epoch : 351, loss = 0.5336694428453499\n",
      "epoch : 352, loss = 0.5334154472770686\n",
      "epoch : 353, loss = 0.5331106058476579\n",
      "epoch : 354, loss = 0.5328192052581227\n",
      "epoch : 355, loss = 0.5325620366799018\n",
      "epoch : 356, loss = 0.5322705996755469\n",
      "epoch : 357, loss = 0.5321441954063244\n",
      "epoch : 358, loss = 0.531969185010974\n",
      "epoch : 359, loss = 0.531625197225964\n",
      "epoch : 360, loss = 0.5313251633315142\n",
      "epoch : 361, loss = 0.5310871311721725\n",
      "epoch : 362, loss = 0.5307903609439547\n",
      "epoch : 363, loss = 0.5305651444243352\n",
      "epoch : 364, loss = 0.530413711126887\n",
      "epoch : 365, loss = 0.530213098520115\n",
      "epoch : 366, loss = 0.5299141487613231\n",
      "epoch : 367, loss = 0.5296191890107801\n",
      "epoch : 368, loss = 0.5293183796444422\n",
      "epoch : 369, loss = 0.5290727676567915\n",
      "epoch : 370, loss = 0.5288992513814021\n",
      "epoch : 371, loss = 0.5286954075336078\n",
      "epoch : 372, loss = 0.5283890719880021\n",
      "epoch : 373, loss = 0.5280861643610915\n",
      "epoch : 374, loss = 0.5278816917752629\n",
      "epoch : 375, loss = 0.5276044673678922\n",
      "epoch : 376, loss = 0.5275179268918968\n",
      "epoch : 377, loss = 0.5272216949610644\n",
      "epoch : 378, loss = 0.526915939335366\n",
      "epoch : 379, loss = 0.5266185016179933\n",
      "epoch : 380, loss = 0.5263912012315067\n",
      "epoch : 381, loss = 0.5261218262253281\n",
      "epoch : 382, loss = 0.5260364762963161\n",
      "epoch : 383, loss = 0.5257430878279201\n",
      "epoch : 384, loss = 0.5254455539306012\n",
      "epoch : 385, loss = 0.5251531020327779\n",
      "epoch : 386, loss = 0.5249030697868584\n",
      "epoch : 387, loss = 0.5246554802619747\n",
      "epoch : 388, loss = 0.5243782737761602\n",
      "epoch : 389, loss = 0.524300613744285\n",
      "epoch : 390, loss = 0.5240558318676034\n",
      "epoch : 391, loss = 0.5237400304694482\n",
      "epoch : 392, loss = 0.5234356159112352\n",
      "epoch : 393, loss = 0.523156324227622\n",
      "epoch : 394, loss = 0.5229332288103051\n",
      "epoch : 395, loss = 0.5228179433033403\n",
      "epoch : 396, loss = 0.5225713951522087\n",
      "epoch : 397, loss = 0.5222757371259538\n",
      "epoch : 398, loss = 0.5219718770882117\n",
      "epoch : 399, loss = 0.521696346630758\n",
      "epoch : 400, loss = 0.52145064183737\n",
      "epoch : 401, loss = 0.5213353625483215\n",
      "epoch : 402, loss = 0.5210981937310883\n",
      "epoch : 403, loss = 0.5208060248821093\n",
      "epoch : 404, loss = 0.5205107441431177\n",
      "epoch : 405, loss = 0.5202385181400966\n",
      "epoch : 406, loss = 0.5199703138159647\n",
      "epoch : 407, loss = 0.5198142609734054\n",
      "epoch : 408, loss = 0.5196791147937159\n",
      "epoch : 409, loss = 0.519335733599771\n",
      "epoch : 410, loss = 0.5190437585427272\n",
      "epoch : 411, loss = 0.5187828614275254\n",
      "epoch : 412, loss = 0.518511945945766\n",
      "epoch : 413, loss = 0.5183144583764551\n",
      "epoch : 414, loss = 0.5181388981094204\n",
      "epoch : 415, loss = 0.5176634415931065\n",
      "epoch : 416, loss = 0.5172046543748738\n",
      "epoch : 417, loss = 0.5167466728968921\n",
      "epoch : 418, loss = 0.5162894913752734\n",
      "epoch : 419, loss = 0.5158466062460441\n",
      "epoch : 420, loss = 0.5154720048524232\n",
      "epoch : 421, loss = 0.5150441936801686\n",
      "epoch : 422, loss = 0.5146634688286505\n",
      "epoch : 423, loss = 0.5142661225545739\n",
      "epoch : 424, loss = 0.5138397257517335\n",
      "epoch : 425, loss = 0.5134602608236777\n",
      "epoch : 426, loss = 0.513261554821043\n",
      "epoch : 427, loss = 0.5131063961878386\n",
      "epoch : 428, loss = 0.5126221818721505\n",
      "epoch : 429, loss = 0.5121714724775093\n",
      "epoch : 430, loss = 0.5117255472652542\n",
      "epoch : 431, loss = 0.5112870967243971\n",
      "epoch : 432, loss = 0.5108388653705352\n",
      "epoch : 433, loss = 0.5104595020159363\n",
      "epoch : 434, loss = 0.5100371234300568\n",
      "epoch : 435, loss = 0.509670566644312\n",
      "epoch : 436, loss = 0.5092717573713283\n",
      "epoch : 437, loss = 0.5088506698427397\n",
      "epoch : 438, loss = 0.5084878078707751\n",
      "epoch : 439, loss = 0.5084358370453917\n",
      "epoch : 440, loss = 0.5080814413160097\n",
      "epoch : 441, loss = 0.5076406674571325\n",
      "epoch : 442, loss = 0.50721007810243\n",
      "epoch : 443, loss = 0.5067677904529668\n",
      "epoch : 444, loss = 0.506326186747502\n",
      "epoch : 445, loss = 0.5058888539340802\n",
      "epoch : 446, loss = 0.5055312655585779\n",
      "epoch : 447, loss = 0.5051332899563636\n",
      "epoch : 448, loss = 0.504724000255738\n",
      "epoch : 449, loss = 0.5043468036594436\n",
      "epoch : 450, loss = 0.503952123230944\n",
      "epoch : 451, loss = 0.5038223394780312\n",
      "epoch : 452, loss = 0.5035636563187487\n",
      "epoch : 453, loss = 0.5031402812289911\n",
      "epoch : 454, loss = 0.5027412499236367\n",
      "epoch : 455, loss = 0.502422973728506\n",
      "epoch : 456, loss = 0.5021179719627722\n",
      "epoch : 457, loss = 0.5018644240593872\n",
      "epoch : 458, loss = 0.5016245362194895\n",
      "epoch : 459, loss = 0.5014090218460485\n",
      "epoch : 460, loss = 0.5011883370529782\n",
      "epoch : 461, loss = 0.5009487102022531\n",
      "epoch : 462, loss = 0.5007092644403317\n",
      "epoch : 463, loss = 0.5004742427966904\n",
      "epoch : 464, loss = 0.5002603968069659\n",
      "epoch : 465, loss = 0.5000213532501967\n",
      "epoch : 466, loss = 0.4997902754542569\n",
      "epoch : 467, loss = 0.4995735070096047\n",
      "epoch : 468, loss = 0.49933477245001695\n",
      "epoch : 469, loss = 0.4990962126164557\n",
      "epoch : 470, loss = 0.49887750621661064\n",
      "epoch : 471, loss = 0.4990392893907946\n",
      "epoch : 472, loss = 0.49879208214229503\n",
      "epoch : 473, loss = 0.49847275048224104\n",
      "epoch : 474, loss = 0.4981698190234516\n",
      "epoch : 475, loss = 0.49786708851255035\n",
      "epoch : 476, loss = 0.4975963577882391\n",
      "epoch : 477, loss = 0.4973587374626788\n",
      "epoch : 478, loss = 0.4971582418439089\n",
      "epoch : 479, loss = 0.49692594995515826\n",
      "epoch : 480, loss = 0.4966885660061743\n",
      "epoch : 481, loss = 0.4964513489177962\n",
      "epoch : 482, loss = 0.4962360906601109\n",
      "epoch : 483, loss = 0.4960064451060009\n",
      "epoch : 484, loss = 0.49576959751130145\n",
      "epoch : 485, loss = 0.4955412020363194\n",
      "epoch : 486, loss = 0.49532529497212296\n",
      "epoch : 487, loss = 0.4950887298021193\n",
      "epoch : 488, loss = 0.4948576237310384\n",
      "epoch : 489, loss = 0.4947460351153294\n",
      "epoch : 490, loss = 0.4947492510178503\n",
      "epoch : 491, loss = 0.49445549672846345\n",
      "epoch : 492, loss = 0.49415475878789983\n",
      "epoch : 493, loss = 0.493854108861008\n",
      "epoch : 494, loss = 0.49360043369102924\n",
      "epoch : 495, loss = 0.49336474262355245\n",
      "epoch : 496, loss = 0.49314275700141236\n",
      "epoch : 497, loss = 0.49292257983874566\n",
      "epoch : 498, loss = 0.49268723786657054\n",
      "epoch : 499, loss = 0.4924558554778933\n",
      "epoch : 500, loss = 0.4922453978946707\n",
      "epoch : 501, loss = 0.4920103218507353\n",
      "epoch : 502, loss = 0.49177539906309864\n",
      "epoch : 503, loss = 0.4915669077449096\n",
      "epoch : 504, loss = 0.491334618832772\n",
      "epoch : 505, loss = 0.4911000345415186\n",
      "epoch : 506, loss = 0.4908821151562581\n",
      "epoch : 507, loss = 0.4906594333831058\n",
      "epoch : 508, loss = 0.49042510673090944\n",
      "epoch : 509, loss = 0.49019964971617663\n",
      "epoch : 510, loss = 0.49002125736645835\n",
      "epoch : 511, loss = 0.4900961034696072\n",
      "epoch : 512, loss = 0.4898012758581525\n",
      "epoch : 513, loss = 0.4895027489453694\n",
      "epoch : 514, loss = 0.4892044157832062\n",
      "epoch : 515, loss = 0.4889497377834773\n",
      "epoch : 516, loss = 0.48871621543678895\n",
      "epoch : 517, loss = 0.48849895019097295\n",
      "epoch : 518, loss = 0.4882779944774877\n",
      "epoch : 519, loss = 0.4880447941100945\n",
      "epoch : 520, loss = 0.48781675766605703\n",
      "epoch : 521, loss = 0.4876065142867767\n",
      "epoch : 522, loss = 0.48737355825513984\n",
      "epoch : 523, loss = 0.4871407443452219\n",
      "epoch : 524, loss = 0.48693578007871374\n",
      "epoch : 525, loss = 0.48670382025523773\n",
      "epoch : 526, loss = 0.48647131962638096\n",
      "epoch : 527, loss = 0.4862533460878062\n",
      "epoch : 528, loss = 0.48603421289047477\n",
      "epoch : 529, loss = 0.4858019498650381\n",
      "epoch : 530, loss = 0.4855793155133811\n",
      "epoch : 531, loss = 0.4853660948846149\n",
      "epoch : 532, loss = 0.4851341396806753\n",
      "epoch : 533, loss = 0.4849023212158182\n",
      "epoch : 534, loss = 0.4846960742161127\n",
      "epoch : 535, loss = 0.4848358028377303\n",
      "epoch : 536, loss = 0.48457856209816375\n",
      "epoch : 537, loss = 0.48428249263288553\n",
      "epoch : 538, loss = 0.4839866143715658\n",
      "epoch : 539, loss = 0.48369092694669785\n",
      "epoch : 540, loss = 0.4834415417396599\n",
      "epoch : 541, loss = 0.48321045381767214\n",
      "epoch : 542, loss = 0.4830108089473846\n",
      "epoch : 543, loss = 0.48278805342914943\n",
      "epoch : 544, loss = 0.48255714596079746\n",
      "epoch : 545, loss = 0.48232637122489186\n",
      "epoch : 546, loss = 0.4820995483730443\n",
      "epoch : 547, loss = 0.4818932597159694\n",
      "epoch : 548, loss = 0.48166277689672055\n",
      "epoch : 549, loss = 0.48143288332406897\n",
      "epoch : 550, loss = 0.4812291627144031\n",
      "epoch : 551, loss = 0.48099890064164064\n",
      "epoch : 552, loss = 0.48076876825729487\n",
      "epoch : 553, loss = 0.4805534593092758\n",
      "epoch : 554, loss = 0.4803833334054184\n",
      "epoch : 555, loss = 0.4804577807976089\n",
      "epoch : 556, loss = 0.4801616838158675\n",
      "epoch : 557, loss = 0.4798677462272441\n",
      "epoch : 558, loss = 0.4795739978617118\n",
      "epoch : 559, loss = 0.4793181009322685\n",
      "epoch : 560, loss = 0.4790886583298859\n",
      "epoch : 561, loss = 0.4788801457854717\n",
      "epoch : 562, loss = 0.4786580131408318\n",
      "epoch : 563, loss = 0.4784288492752165\n",
      "epoch : 564, loss = 0.4782061510278131\n",
      "epoch : 565, loss = 0.4779974914101048\n",
      "epoch : 566, loss = 0.47776853783148726\n",
      "epoch : 567, loss = 0.4775417654734964\n",
      "epoch : 568, loss = 0.4773388765776101\n",
      "epoch : 569, loss = 0.4771101980219776\n",
      "epoch : 570, loss = 0.4768816423039771\n",
      "epoch : 571, loss = 0.4766641093970224\n",
      "epoch : 572, loss = 0.47645135717069403\n",
      "epoch : 573, loss = 0.4762230072469006\n",
      "epoch : 574, loss = 0.4760073702081258\n",
      "epoch : 575, loss = 0.4757944958034233\n",
      "epoch : 576, loss = 0.4755664152979847\n",
      "epoch : 577, loss = 0.4753384551872547\n",
      "epoch : 578, loss = 0.47512928473392224\n",
      "epoch : 579, loss = 0.47524166528799305\n",
      "epoch : 580, loss = 0.4749883258546284\n",
      "epoch : 581, loss = 0.4746919201980135\n",
      "epoch : 582, loss = 0.47432048502607216\n",
      "epoch : 583, loss = 0.47394949084422316\n",
      "epoch : 584, loss = 0.47367606502483306\n",
      "epoch : 585, loss = 0.47339606428450487\n",
      "epoch : 586, loss = 0.4731162787611214\n",
      "epoch : 587, loss = 0.4728367080732688\n",
      "epoch : 588, loss = 0.47256262106844854\n",
      "epoch : 589, loss = 0.47229669298617705\n",
      "epoch : 590, loss = 0.4720177107387877\n",
      "epoch : 591, loss = 0.47173894351424\n",
      "epoch : 592, loss = 0.471460390919731\n",
      "epoch : 593, loss = 0.4711820525661258\n",
      "epoch : 594, loss = 0.47091076967254736\n",
      "epoch : 595, loss = 0.47089843143184945\n",
      "epoch : 596, loss = 0.47078415301494997\n",
      "epoch : 597, loss = 0.4704164977117016\n",
      "epoch : 598, loss = 0.4700492826147921\n",
      "epoch : 599, loss = 0.4696825069782375\n",
      "epoch : 600, loss = 0.46940436783827966\n",
      "epoch : 601, loss = 0.46912752092927634\n",
      "epoch : 602, loss = 0.46885088771937383\n",
      "epoch : 603, loss = 0.4685791107446378\n",
      "epoch : 604, loss = 0.46831737327527273\n",
      "epoch : 605, loss = 0.4680471180064511\n",
      "epoch : 606, loss = 0.4677756068634509\n",
      "epoch : 607, loss = 0.4675018607926715\n",
      "epoch : 608, loss = 0.46722642048476615\n",
      "epoch : 609, loss = 0.46695578787799674\n",
      "epoch : 610, loss = 0.46669941021511585\n",
      "epoch : 611, loss = 0.46667685245804413\n",
      "epoch : 612, loss = 0.4665277079288719\n",
      "epoch : 613, loss = 0.46616429798817394\n",
      "epoch : 614, loss = 0.46580132592906454\n",
      "epoch : 615, loss = 0.4654590963734853\n",
      "epoch : 616, loss = 0.46518532674330704\n",
      "epoch : 617, loss = 0.46493153267022186\n",
      "epoch : 618, loss = 0.46465911631833284\n",
      "epoch : 619, loss = 0.46438762432063646\n",
      "epoch : 620, loss = 0.4641187858885767\n",
      "epoch : 621, loss = 0.4638565743316448\n",
      "epoch : 622, loss = 0.4635931469323073\n",
      "epoch : 623, loss = 0.4633255113272593\n",
      "epoch : 624, loss = 0.4630531384190373\n",
      "epoch : 625, loss = 0.4627820909747294\n",
      "epoch : 626, loss = 0.46251513250307486\n",
      "epoch : 627, loss = 0.46225730441628643\n",
      "epoch : 628, loss = 0.4621007494235846\n",
      "epoch : 629, loss = 0.462130286007037\n",
      "epoch : 630, loss = 0.46177120540248756\n",
      "epoch : 631, loss = 0.46141256037924777\n",
      "epoch : 632, loss = 0.46105435013733626\n",
      "epoch : 633, loss = 0.46077870642722607\n",
      "epoch : 634, loss = 0.460508201809014\n",
      "epoch : 635, loss = 0.46023790721803726\n",
      "epoch : 636, loss = 0.4599739723467483\n",
      "epoch : 637, loss = 0.4597230102026056\n",
      "epoch : 638, loss = 0.45945327316266776\n",
      "epoch : 639, loss = 0.4591855247076714\n",
      "epoch : 640, loss = 0.4589204472248732\n",
      "epoch : 641, loss = 0.45865132307550227\n",
      "epoch : 642, loss = 0.45839221082223747\n",
      "epoch : 643, loss = 0.45814573836166883\n",
      "epoch : 644, loss = 0.45791295831757867\n",
      "epoch : 645, loss = 0.4579826000752082\n",
      "epoch : 646, loss = 0.4576276834451758\n",
      "epoch : 647, loss = 0.45727319939307787\n",
      "epoch : 648, loss = 0.456924451722916\n",
      "epoch : 649, loss = 0.4566684971773251\n",
      "epoch : 650, loss = 0.45640839162628427\n",
      "epoch : 651, loss = 0.4561438141397195\n",
      "epoch : 652, loss = 0.4558767404012663\n",
      "epoch : 653, loss = 0.45562092788806785\n",
      "epoch : 654, loss = 0.4553683750628733\n",
      "epoch : 655, loss = 0.45510185134839654\n",
      "epoch : 656, loss = 0.45483673059439156\n",
      "epoch : 657, loss = 0.4545753339967403\n",
      "epoch : 658, loss = 0.4543094157557809\n",
      "epoch : 659, loss = 0.4540588396924431\n",
      "epoch : 660, loss = 0.4538034024799167\n",
      "epoch : 661, loss = 0.4535380314247386\n",
      "epoch : 662, loss = 0.45327286693955887\n",
      "epoch : 663, loss = 0.45301268825522945\n",
      "epoch : 664, loss = 0.45276588087923564\n",
      "epoch : 665, loss = 0.45292518911462565\n",
      "epoch : 666, loss = 0.45261788466783526\n",
      "epoch : 667, loss = 0.45226326594215327\n",
      "epoch : 668, loss = 0.45191424314928247\n",
      "epoch : 669, loss = 0.4515718257503304\n",
      "epoch : 670, loss = 0.4513194691102303\n",
      "epoch : 671, loss = 0.4510665085058983\n",
      "epoch : 672, loss = 0.4508033826059984\n",
      "epoch : 673, loss = 0.45054022998429827\n",
      "epoch : 674, loss = 0.45028176342946385\n",
      "epoch : 675, loss = 0.45002504693688383\n",
      "epoch : 676, loss = 0.44977734055473684\n",
      "epoch : 677, loss = 0.4495175683910514\n",
      "epoch : 678, loss = 0.4492584990840888\n",
      "epoch : 679, loss = 0.4489964816505634\n",
      "epoch : 680, loss = 0.4487397114157282\n",
      "epoch : 681, loss = 0.44876158317737247\n",
      "epoch : 682, loss = 0.44859726246829956\n",
      "epoch : 683, loss = 0.4482485388472653\n",
      "epoch : 684, loss = 0.44790354307718167\n",
      "epoch : 685, loss = 0.4475763342111514\n",
      "epoch : 686, loss = 0.4473160943582888\n",
      "epoch : 687, loss = 0.44707164325390747\n",
      "epoch : 688, loss = 0.44681268897151266\n",
      "epoch : 689, loss = 0.44655669637309364\n",
      "epoch : 690, loss = 0.44629665924367456\n",
      "epoch : 691, loss = 0.44603682338247297\n",
      "epoch : 692, loss = 0.4458033406817238\n",
      "epoch : 693, loss = 0.4455431989355201\n",
      "epoch : 694, loss = 0.44528389235865\n",
      "epoch : 695, loss = 0.4450282739639095\n",
      "epoch : 696, loss = 0.44477153646988654\n",
      "epoch : 697, loss = 0.44452881699241814\n",
      "epoch : 698, loss = 0.44445712503672674\n",
      "epoch : 699, loss = 0.4443849415551369\n",
      "epoch : 700, loss = 0.4440437182295904\n",
      "epoch : 701, loss = 0.4437029150215292\n",
      "epoch : 702, loss = 0.4433680576371452\n",
      "epoch : 703, loss = 0.4431230792566263\n",
      "epoch : 704, loss = 0.44286987109959314\n",
      "epoch : 705, loss = 0.4426125141632492\n",
      "epoch : 706, loss = 0.44235651950915245\n",
      "epoch : 707, loss = 0.44210397930950734\n",
      "epoch : 708, loss = 0.4418651118933978\n",
      "epoch : 709, loss = 0.44161063858630123\n",
      "epoch : 710, loss = 0.44135843400311014\n",
      "epoch : 711, loss = 0.44110351592137964\n",
      "epoch : 712, loss = 0.4408474560165072\n",
      "epoch : 713, loss = 0.4406080990176176\n",
      "epoch : 714, loss = 0.4403692326004331\n",
      "epoch : 715, loss = 0.4401270018181145\n",
      "epoch : 716, loss = 0.44022489203903253\n",
      "epoch : 717, loss = 0.4398878121800922\n",
      "epoch : 718, loss = 0.4395511482861026\n",
      "epoch : 719, loss = 0.4392148994438576\n",
      "epoch : 720, loss = 0.43896734269892623\n",
      "epoch : 721, loss = 0.43871379285099094\n",
      "epoch : 722, loss = 0.4384639764106565\n",
      "epoch : 723, loss = 0.4382098275089576\n",
      "epoch : 724, loss = 0.4379757919247361\n",
      "epoch : 725, loss = 0.43772599813543195\n",
      "epoch : 726, loss = 0.43747420667880954\n",
      "epoch : 727, loss = 0.4372207621882578\n",
      "epoch : 728, loss = 0.4369689108156343\n",
      "epoch : 729, loss = 0.43673826436627006\n",
      "epoch : 730, loss = 0.43649517533789806\n",
      "epoch : 731, loss = 0.4362424258341603\n",
      "epoch : 732, loss = 0.435994426863482\n",
      "epoch : 733, loss = 0.43574292742849907\n",
      "epoch : 734, loss = 0.4355046405164321\n",
      "epoch : 735, loss = 0.43529429585053825\n",
      "epoch : 736, loss = 0.4353534574837944\n",
      "epoch : 737, loss = 0.4351906404245167\n",
      "epoch : 738, loss = 0.4348919339138981\n",
      "epoch : 739, loss = 0.43459772146287984\n",
      "epoch : 740, loss = 0.43430375201731786\n",
      "epoch : 741, loss = 0.4340711055883577\n",
      "epoch : 742, loss = 0.43384409876082297\n",
      "epoch : 743, loss = 0.433617215010821\n",
      "epoch : 744, loss = 0.43340657549441924\n",
      "epoch : 745, loss = 0.4331927196582558\n",
      "epoch : 746, loss = 0.4329663312900413\n",
      "epoch : 747, loss = 0.43275264906615085\n",
      "epoch : 748, loss = 0.4325379163379364\n",
      "epoch : 749, loss = 0.43231533906678454\n",
      "epoch : 750, loss = 0.4320899904796852\n",
      "epoch : 751, loss = 0.43187601887636146\n",
      "epoch : 752, loss = 0.4316630332896234\n",
      "epoch : 753, loss = 0.4314411082431192\n",
      "epoch : 754, loss = 0.43122248385276724\n",
      "epoch : 755, loss = 0.43106990580936405\n",
      "epoch : 756, loss = 0.43111662833210673\n",
      "epoch : 757, loss = 0.4308245270345606\n",
      "epoch : 758, loss = 0.4305326691988769\n",
      "epoch : 759, loss = 0.4302410543807122\n",
      "epoch : 760, loss = 0.4300032973119677\n",
      "epoch : 761, loss = 0.4297780682151016\n",
      "epoch : 762, loss = 0.4295717708665626\n",
      "epoch : 763, loss = 0.42935695757600073\n",
      "epoch : 764, loss = 0.4291319610254638\n",
      "epoch : 765, loss = 0.4289136569891311\n",
      "epoch : 766, loss = 0.42870839360252305\n",
      "epoch : 767, loss = 0.4284868507495156\n",
      "epoch : 768, loss = 0.4282622602022595\n",
      "epoch : 769, loss = 0.4280507759576566\n",
      "epoch : 770, loss = 0.42783825153758986\n",
      "epoch : 771, loss = 0.4276181084252685\n",
      "epoch : 772, loss = 0.42739825957310495\n",
      "epoch : 773, loss = 0.4271944830718827\n",
      "epoch : 774, loss = 0.4269719275868744\n",
      "epoch : 775, loss = 0.4267510117026358\n",
      "epoch : 776, loss = 0.42653586714387387\n",
      "epoch : 777, loss = 0.4263509485820698\n",
      "epoch : 778, loss = 0.4264555253739813\n",
      "epoch : 779, loss = 0.4261773203401456\n",
      "epoch : 780, loss = 0.425899324548476\n",
      "epoch : 781, loss = 0.42562153753623233\n",
      "epoch : 782, loss = 0.42537842087094224\n",
      "epoch : 783, loss = 0.42516616156299025\n",
      "epoch : 784, loss = 0.42498225503376563\n",
      "epoch : 785, loss = 0.42478169028381785\n",
      "epoch : 786, loss = 0.42456954560019206\n",
      "epoch : 787, loss = 0.4243574920793216\n",
      "epoch : 788, loss = 0.42414851285815686\n",
      "epoch : 789, loss = 0.4239629741121601\n",
      "epoch : 790, loss = 0.42375111523950015\n",
      "epoch : 791, loss = 0.4235393464958148\n",
      "epoch : 792, loss = 0.42334072869787864\n",
      "epoch : 793, loss = 0.4231451189558625\n",
      "epoch : 794, loss = 0.4229334924776231\n",
      "epoch : 795, loss = 0.42272427541497526\n",
      "epoch : 796, loss = 0.4225367795069729\n",
      "epoch : 797, loss = 0.4223284546830149\n",
      "epoch : 798, loss = 0.42211711112613765\n",
      "epoch : 799, loss = 0.4219147065294797\n",
      "epoch : 800, loss = 0.42184223559430234\n",
      "epoch : 801, loss = 0.4218458571825701\n",
      "epoch : 802, loss = 0.42156985185202883\n",
      "epoch : 803, loss = 0.42129405499245337\n",
      "epoch : 804, loss = 0.42101846613142263\n",
      "epoch : 805, loss = 0.4207784089264312\n",
      "epoch : 806, loss = 0.42056788051639493\n",
      "epoch : 807, loss = 0.42038866594279034\n",
      "epoch : 808, loss = 0.42018590797202715\n",
      "epoch : 809, loss = 0.4199751412262132\n",
      "epoch : 810, loss = 0.41976446400202\n",
      "epoch : 811, loss = 0.41956093196529143\n",
      "epoch : 812, loss = 0.4193727859239704\n",
      "epoch : 813, loss = 0.4191622980216247\n",
      "epoch : 814, loss = 0.4189519241191741\n",
      "epoch : 815, loss = 0.4187592295408323\n",
      "epoch : 816, loss = 0.41856043367413165\n",
      "epoch : 817, loss = 0.41835017157740945\n",
      "epoch : 818, loss = 0.4181446843932132\n",
      "epoch : 819, loss = 0.41795925470486206\n",
      "epoch : 820, loss = 0.41774930870449634\n",
      "epoch : 821, loss = 0.4175393228905653\n",
      "epoch : 822, loss = 0.4173418285653574\n",
      "epoch : 823, loss = 0.41733789833116314\n",
      "epoch : 824, loss = 0.4172772464086496\n",
      "epoch : 825, loss = 0.41700339871224956\n",
      "epoch : 826, loss = 0.41672975869474027\n",
      "epoch : 827, loss = 0.4164563258751419\n",
      "epoch : 828, loss = 0.4162134048191514\n",
      "epoch : 829, loss = 0.4160038631774613\n",
      "epoch : 830, loss = 0.41582754542699063\n",
      "epoch : 831, loss = 0.4156206371387903\n",
      "epoch : 832, loss = 0.4154112087686378\n",
      "epoch : 833, loss = 0.4152033548740143\n",
      "epoch : 834, loss = 0.4150066165259809\n",
      "epoch : 835, loss = 0.41481294585868783\n",
      "epoch : 836, loss = 0.4146037903111138\n",
      "epoch : 837, loss = 0.4143965423184899\n",
      "epoch : 838, loss = 0.4142098650049773\n",
      "epoch : 839, loss = 0.4140169129630597\n",
      "epoch : 840, loss = 0.4138079473751358\n",
      "epoch : 841, loss = 0.41359954414966493\n",
      "epoch : 842, loss = 0.41339461591783777\n",
      "epoch : 843, loss = 0.41320223694811203\n",
      "epoch : 844, loss = 0.4131728718110411\n",
      "epoch : 845, loss = 0.41311805727427975\n",
      "epoch : 846, loss = 0.4128355161688912\n",
      "epoch : 847, loss = 0.41256388972256214\n",
      "epoch : 848, loss = 0.4122924693270623\n",
      "epoch : 849, loss = 0.4120826916656107\n",
      "epoch : 850, loss = 0.4118743046308159\n",
      "epoch : 851, loss = 0.41166600427500666\n",
      "epoch : 852, loss = 0.4114841346874389\n",
      "epoch : 853, loss = 0.4112897807623484\n",
      "epoch : 854, loss = 0.4110815802229247\n",
      "epoch : 855, loss = 0.4108734671525821\n",
      "epoch : 856, loss = 0.410673897781126\n",
      "epoch : 857, loss = 0.41048711593226017\n",
      "epoch : 858, loss = 0.41027918396899565\n",
      "epoch : 859, loss = 0.41007133855120975\n",
      "epoch : 860, loss = 0.4098780607672147\n",
      "epoch : 861, loss = 0.4096961280246406\n",
      "epoch : 862, loss = 0.40948838094853146\n",
      "epoch : 863, loss = 0.4092807212180603\n",
      "epoch : 864, loss = 0.4090734562358295\n",
      "epoch : 865, loss = 0.4088871951277137\n",
      "epoch : 866, loss = 0.4088178186711477\n",
      "epoch : 867, loss = 0.4087949014532001\n",
      "epoch : 868, loss = 0.4085208619396437\n",
      "epoch : 869, loss = 0.40825126428269065\n",
      "epoch : 870, loss = 0.4079818718239152\n",
      "epoch : 871, loss = 0.40777313446139385\n",
      "epoch : 872, loss = 0.4075659541484817\n",
      "epoch : 873, loss = 0.4073588599320037\n",
      "epoch : 874, loss = 0.407171338588387\n",
      "epoch : 875, loss = 0.4069745035952632\n",
      "epoch : 876, loss = 0.40676680162619655\n",
      "epoch : 877, loss = 0.4065517630101538\n",
      "epoch : 878, loss = 0.40632012229020076\n",
      "epoch : 879, loss = 0.4060832400656758\n",
      "epoch : 880, loss = 0.40584645135149644\n",
      "epoch : 881, loss = 0.40563724860767836\n",
      "epoch : 882, loss = 0.4054100423091956\n",
      "epoch : 883, loss = 0.40517335923883974\n",
      "epoch : 884, loss = 0.4049367704198612\n",
      "epoch : 885, loss = 0.40470027508208384\n",
      "epoch : 886, loss = 0.40450284503775336\n",
      "epoch : 887, loss = 0.40455669058312327\n",
      "epoch : 888, loss = 0.40425278369652357\n",
      "epoch : 889, loss = 0.40394908600643337\n",
      "epoch : 890, loss = 0.4036646654898136\n",
      "epoch : 891, loss = 0.4034378713639108\n",
      "epoch : 892, loss = 0.4032293318355405\n",
      "epoch : 893, loss = 0.4029931626105341\n",
      "epoch : 894, loss = 0.40275708797744203\n",
      "epoch : 895, loss = 0.40252110716276457\n",
      "epoch : 896, loss = 0.40229617644893356\n",
      "epoch : 897, loss = 0.40208640007800633\n",
      "epoch : 898, loss = 0.4018505244353703\n",
      "epoch : 899, loss = 0.40161474337749503\n",
      "epoch : 900, loss = 0.4013790561338275\n",
      "epoch : 901, loss = 0.4011564496404107\n",
      "epoch : 902, loss = 0.40118833626659756\n",
      "epoch : 903, loss = 0.401019564982137\n",
      "epoch : 904, loss = 0.4007171185273154\n",
      "epoch : 905, loss = 0.4004148817529071\n",
      "epoch : 906, loss = 0.40011285427035936\n",
      "epoch : 907, loss = 0.3998985506929738\n",
      "epoch : 908, loss = 0.3996632821486453\n",
      "epoch : 909, loss = 0.39943821553740155\n",
      "epoch : 910, loss = 0.39922015166598834\n",
      "epoch : 911, loss = 0.39898502274744935\n",
      "epoch : 912, loss = 0.3987499876620899\n",
      "epoch : 913, loss = 0.39852745914008897\n",
      "epoch : 914, loss = 0.3983073317011983\n",
      "epoch : 915, loss = 0.3980724362713179\n",
      "epoch : 916, loss = 0.3978376346702889\n",
      "epoch : 917, loss = 0.397623894409749\n",
      "epoch : 918, loss = 0.39758146995878973\n",
      "epoch : 919, loss = 0.3974841637257343\n",
      "epoch : 920, loss = 0.39718320100828414\n",
      "epoch : 921, loss = 0.3968824483694405\n",
      "epoch : 922, loss = 0.39658190541704064\n",
      "epoch : 923, loss = 0.3963623037684878\n",
      "epoch : 924, loss = 0.3961279195843775\n",
      "epoch : 925, loss = 0.39590862483708467\n",
      "epoch : 926, loss = 0.3956865480301307\n",
      "epoch : 927, loss = 0.39545230341501086\n",
      "epoch : 928, loss = 0.39521815274949\n",
      "epoch : 929, loss = 0.39500171439069365\n",
      "epoch : 930, loss = 0.3947772562286463\n",
      "epoch : 931, loss = 0.39454324522388895\n",
      "epoch : 932, loss = 0.3943093281964307\n",
      "epoch : 933, loss = 0.3941054706739224\n",
      "epoch : 934, loss = 0.39397978180651483\n",
      "epoch : 935, loss = 0.3939631504393744\n",
      "epoch : 936, loss = 0.39366367318085443\n",
      "epoch : 937, loss = 0.39336440642754306\n",
      "epoch : 938, loss = 0.3930653497836236\n",
      "epoch : 939, loss = 0.39283917056845385\n",
      "epoch : 940, loss = 0.39260567047405204\n",
      "epoch : 941, loss = 0.39239263974107613\n",
      "epoch : 942, loss = 0.3921660596627138\n",
      "epoch : 943, loss = 0.39193269931794694\n",
      "epoch : 944, loss = 0.39169943316304295\n",
      "epoch : 945, loss = 0.39149107511519116\n",
      "epoch : 946, loss = 0.39127024268327576\n",
      "epoch : 947, loss = 0.3910370811186038\n",
      "epoch : 948, loss = 0.39080401461291653\n",
      "epoch : 949, loss = 0.3905710424125193\n",
      "epoch : 950, loss = 0.39036756962027386\n",
      "epoch : 951, loss = 0.3903300652979674\n",
      "epoch : 952, loss = 0.3902099435770139\n",
      "epoch : 953, loss = 0.38991207471205913\n",
      "epoch : 954, loss = 0.3896144168597584\n",
      "epoch : 955, loss = 0.3893243901451498\n",
      "epoch : 956, loss = 0.38912066583952143\n",
      "epoch : 957, loss = 0.38888801414038315\n",
      "epoch : 958, loss = 0.38865545818038655\n",
      "epoch : 959, loss = 0.38842299719846085\n",
      "epoch : 960, loss = 0.3882041172691156\n",
      "epoch : 961, loss = 0.3879955105976207\n",
      "epoch : 962, loss = 0.3877631544660743\n",
      "epoch : 963, loss = 0.38753089419792675\n",
      "epoch : 964, loss = 0.38729872903377827\n",
      "epoch : 965, loss = 0.3870858056689407\n",
      "epoch : 966, loss = 0.38688827261110253\n",
      "epoch : 967, loss = 0.38693972772418017\n",
      "epoch : 968, loss = 0.38664327034421425\n",
      "epoch : 969, loss = 0.38634702421543304\n",
      "epoch : 970, loss = 0.3860509889366336\n",
      "epoch : 971, loss = 0.38583897510786425\n",
      "epoch : 972, loss = 0.38560722868004516\n",
      "epoch : 973, loss = 0.3853901450610125\n",
      "epoch : 974, loss = 0.3851711778077117\n",
      "epoch : 975, loss = 0.38493957245948573\n",
      "epoch : 976, loss = 0.38470806255557155\n",
      "epoch : 977, loss = 0.38449506355678686\n",
      "epoch : 978, loss = 0.3842724900936946\n",
      "epoch : 979, loss = 0.3840411215109364\n",
      "epoch : 980, loss = 0.3838098484640353\n",
      "epoch : 981, loss = 0.38361111516641605\n",
      "epoch : 982, loss = 0.38338478647700514\n",
      "epoch : 983, loss = 0.3831536188954535\n",
      "epoch : 984, loss = 0.3829225477703699\n",
      "epoch : 985, loss = 0.3826993367377264\n",
      "epoch : 986, loss = 0.3828260309375746\n",
      "epoch : 987, loss = 0.38257187075254184\n",
      "epoch : 988, loss = 0.38226744732761925\n",
      "epoch : 989, loss = 0.3819731701938297\n",
      "epoch : 990, loss = 0.3816836703193345\n",
      "epoch : 991, loss = 0.3814758993385431\n",
      "epoch : 992, loss = 0.3812501438025274\n",
      "epoch : 993, loss = 0.3810222315050157\n",
      "epoch : 994, loss = 0.3808156103038738\n",
      "epoch : 995, loss = 0.38059378215895384\n",
      "epoch : 996, loss = 0.3803652057699337\n",
      "epoch : 997, loss = 0.38013752202540757\n",
      "epoch : 998, loss = 0.37993622844601355\n",
      "epoch : 999, loss = 0.37971843057061727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = [0,0,0,1]\n",
    "model = DeepNeuralNet(\n",
    "    input_size=2,\n",
    "    hidden_size=8,\n",
    "    output_size=1,\n",
    "    Lambda=0.05,\n",
    "    learning_rate=0.001,\n",
    "    epoches=1000,\n",
    "    hidden_layer=4\n",
    ")\n",
    "model.fit(X,Y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80882e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
